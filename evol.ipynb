{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dc576cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5658cc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Path(\"/home/konstanty/STUDIA/masters_1_sem/rob3/data_odometry_velodyne\")\n",
    "predictions = Path(\"/home/konstanty/STUDIA/masters_1_sem/rob3/semantic-segmentation/predictions/\")\n",
    "with open(\"semantic-kitti.yaml\", \"r\") as f:\n",
    "    kitty_conf = yaml.load(f, yaml.Loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07f3aa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(file_path):\n",
    "    labels = np.fromfile(file_path, dtype=np.uint32)\n",
    "    semantic_labels = labels & 0xFFFF  # mask lower 16 bits\n",
    "    instance_ids = labels >> 16  # upper 16 bits\n",
    "    return semantic_labels, instance_ids\n",
    "def translate_element(x):\n",
    "    translation_key =kitty_conf[\"learning_map\"]\n",
    "    return translation_key.get(x, x) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "513022c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = frame_files = list((predictions / \"sequences/08/predictions\").iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c6d6839",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_files = random.sample(files, int(len(files) * 0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e3ff320",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for f in sampled_files:\n",
    "    label_file = (\n",
    "        dataset\n",
    "        / \"dataset\"\n",
    "        / \"sequences\"\n",
    "        / f.parents[1].stem\n",
    "        / \"labels\"\n",
    "        / (f.stem + \".label\")\n",
    "    )\n",
    "    a, _ = load_labels(label_file)\n",
    "\n",
    "    l.append(np.vectorize(translate_element)(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17116caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = np.concatenate(l, axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "975ac03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrices = [np.load(f) for f in sampled_files]\n",
    "M = np.concatenate(matrices, axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cf6c11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fitness(w):\n",
    "  # Ensure w is a numpy array for operations like M*w\n",
    "  w_array = np.array(w)\n",
    "  if M.shape[1] != w_array.shape[0]:\n",
    "      raise ValueError(\"M and w dimensions are incompatible for multiplication\")\n",
    "  return (np.mean(np.argmax((M*w_array),axis=1) == L),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb194bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_mIoU(w):\n",
    "    # Ensure w is a numpy array for vectorized operations\n",
    "    w_array = np.array(w)\n",
    "\n",
    "    # 1. Apply weights and get predictions\n",
    "    # Assuming M is (num_samples, num_classes) and w_array is (num_classes,)\n",
    "    # If M is (num_samples, num_features) and w is (num_features,),\n",
    "    # you might need to reshape M or w, or apply a matrix multiplication.\n",
    "    # The original `M*w` suggests element-wise multiplication or broadcasting.\n",
    "    # Let's assume `M` contains the pre-weighted scores if `w` is applied earlier,\n",
    "    # or `w` scales the class-specific scores in `M`.\n",
    "    # A common interpretation for `M*w` where `w` is weights for classes:\n",
    "    # If M is (num_samples, num_classes), and w is (num_classes,), then M * w\n",
    "    # would broadcast w across rows, scaling each class's score.\n",
    "    # Example: If M[i,j] is the score for sample i, class j, and w[j] is the weight for class j.\n",
    "    weighted_scores = M * w_array\n",
    "\n",
    "    # Get the predicted class for each sample/pixel\n",
    "    predictions = np.argmax(weighted_scores, axis=1)\n",
    "\n",
    "    unique_classes = kitty_conf[\"learning_map\"]\n",
    "    iou_per_class = []\n",
    "\n",
    "    for cls in unique_classes:\n",
    "        # True Positives: Pixels correctly predicted as class `cls`\n",
    "        tp = np.sum((predictions == cls) & (L == cls))\n",
    "\n",
    "        # False Positives: Pixels predicted as class `cls` but are actually other classes\n",
    "        fp = np.sum((predictions == cls) & (L != cls))\n",
    "\n",
    "        # False Negatives: Pixels that are class `cls` but predicted as other classes\n",
    "        fn = np.sum((predictions != cls) & (L == cls))\n",
    "\n",
    "        # Calculate IoU for the current class\n",
    "        denominator = tp + fp + fn\n",
    "        if denominator == 0:\n",
    "            iou = 1.0  # If there are no true positives, false positives, or false negatives for this class,\n",
    "        # and it's not present in ground truth or predictions, IoU is 1.0.\n",
    "        # This case needs careful consideration. If the class is not present in L at all,\n",
    "        # it's often ignored. If it's present but not predicted/true, then 0.\n",
    "        # For simplicity, if the denominator is 0, it means the class was\n",
    "        # neither present in ground truth nor predicted, so IoU is 1.\n",
    "        # However, a common practice is to only calculate for classes present in ground truth.\n",
    "        else:\n",
    "            iou = tp / denominator\n",
    "        iou_per_class.append(iou)\n",
    "\n",
    "    if not iou_per_class:\n",
    "        return (0.0,)  # No classes found, mIoU is 0\n",
    "\n",
    "    mIoU = np.mean(iou_per_class)\n",
    "    return (mIoU,)  # DEAP fitness functions must return a tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd32be36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# M_tensor = torch.tensor(M, dtype=torch.float32, device=\"cuda\")  # shape: (N, 19)\n",
    "# y_tensor = torch.tensor(L, dtype=torch.long, device=\"cuda\")  # shape: (N,)\n",
    "\n",
    "# def evaluate(individual):\n",
    "#     w = torch.tensor(individual, dtype=torch.float32, device=\"cuda\")  # shape: (19,)\n",
    "    \n",
    "#     logits = M_tensor * w  # shape: (N, 19), broadcasted\n",
    "    \n",
    "#     predictions = torch.argmax(logits, dim=1)  # shape: (N,)\n",
    "    \n",
    "#     accuracy = (predictions == y_tensor).float().mean().item()\n",
    "    \n",
    "#     return (accuracy,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b9529a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(np.float64(0.7829675333335407),)\n",
      "(np.float64(0.8068435580726168),)\n",
      "(np.float64(0.7909755121285638),)\n",
      "(np.float64(0.8068141635887778),)\n",
      "(np.float64(0.8065411965294897),)\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "\tw = np.random.random(19)\n",
    "\tprint(fitness_mIoU(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "879e6c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deap import base, creator, tools, algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe0ab75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tnevals\n",
      "0  \t100   \n",
      "1  \t63    \n",
      "2  \t55    \n",
      "3  \t62    \n",
      "4  \t63    \n",
      "5  \t57    \n",
      "6  \t64    \n",
      "7  \t55    \n",
      "8  \t72    \n",
      "9  \t64    \n",
      "10 \t67    \n",
      "11 \t44    \n",
      "12 \t66    \n",
      "13 \t64    \n",
      "14 \t66    \n",
      "15 \t60    \n"
     ]
    }
   ],
   "source": [
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))  # maximize accuracy\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"attr_float\", lambda: np.random.uniform(0.01, 50.0))  # avoid 0\n",
    "toolbox.register(\n",
    "    \"individual\", tools.initRepeat, creator.Individual, toolbox.attr_float, n=19\n",
    ")\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "toolbox.register(\"evaluate\", fitness_mIoU)\n",
    "toolbox.register(\"mate\", tools.cxBlend, alpha=0.5)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "# Optional: enforce positivity after mutation\n",
    "def repair(individual):\n",
    "    # This function should ensure the output is an Individual object\n",
    "    repaired_list = list(individual) # Ensure it's a list for modification\n",
    "    for i in range(len(repaired_list)):\n",
    "        if repaired_list[i] <= 0:\n",
    "            repaired_list[i] = np.random.uniform(0.01, 1.0)\n",
    "    return creator.Individual(repaired_list) # Cast back to Individual\n",
    "\n",
    "# Decorating to enforce constraints\n",
    "def safe_mutate(individual):\n",
    "    mutant, = tools.mutGaussian(individual, mu=1.0, sigma=0.5, indpb=0.2)\n",
    "    # Ensure that `repaired` is an instance of creator.Individual\n",
    "    repaired = repair(mutant) # repair now returns an Individual\n",
    "    return repaired,  # NOTE: this is a TUPLE!\n",
    "\n",
    "toolbox.register(\"mutate\", safe_mutate)\n",
    "\n",
    "population = toolbox.population(n=100)\n",
    "result, log = algorithms.eaSimple(\n",
    "    population, toolbox, cxpb=0.5, mutpb=0.2, ngen=40, verbose=True\n",
    ")\n",
    "# 5. Get best individual\n",
    "best_ind = tools.selBest(result, k=1)[0]\n",
    "print(\"Best individual (weights):\", best_ind)\n",
    "print(\"Accuracy:\", fitness(best_ind)[0])\n",
    "print(\"miou:\", fitness_mIoU(best_ind)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e39185b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No mutation accuracy 0.6440669137069079\n",
      "No mutation miou 0.8094430504102429\n"
     ]
    }
   ],
   "source": [
    "\n",
    "weighted_scores = M\n",
    "\n",
    "# Get the predicted class for each sample/pixel\n",
    "predictions = np.argmax(weighted_scores, axis=1)\n",
    "\n",
    "unique_classes = kitty_conf['learning_map']\n",
    "iou_per_class = []\n",
    "\n",
    "for cls in unique_classes:\n",
    "\t# True Positives: Pixels correctly predicted as class `cls`\n",
    "\ttp = np.sum((predictions == cls) & (L == cls))\n",
    "\n",
    "\t# False Positives: Pixels predicted as class `cls` but are actually other classes\n",
    "\tfp = np.sum((predictions == cls) & (L != cls))\n",
    "\n",
    "\t# False Negatives: Pixels that are class `cls` but predicted as other classes\n",
    "\tfn = np.sum((predictions != cls) & (L == cls))\n",
    "\n",
    "\t# Calculate IoU for the current class\n",
    "\tdenominator = tp + fp + fn\n",
    "\tif denominator == 0:\n",
    "\t\tiou = 1.0 # If there are no true positives, false positives, or false negatives for this class,\n",
    "\t\t\t\t\t# and it's not present in ground truth or predictions, IoU is 1.0.\n",
    "\t\t\t\t\t# This case needs careful consideration. If the class is not present in L at all,\n",
    "\t\t\t\t\t# it's often ignored. If it's present but not predicted/true, then 0.\n",
    "\t\t\t\t\t# For simplicity, if the denominator is 0, it means the class was\n",
    "\t\t\t\t\t# neither present in ground truth nor predicted, so IoU is 1.\n",
    "\t\t\t\t\t# However, a common practice is to only calculate for classes present in ground truth.\n",
    "\telse:\n",
    "\t\tiou = tp / denominator\n",
    "\tiou_per_class.append(iou)\n",
    "\n",
    "if not iou_per_class:\n",
    "\tprint(0.0,) # No classes found, mIoU is 0\n",
    "\n",
    "mIoU = np.mean(iou_per_class)\n",
    "print(\"No mutation accuracy\", np.mean(np.argmax((M),axis=1) == L))\n",
    "print(\"No mutation miou\", mIoU)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
